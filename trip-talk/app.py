import gradio as gr
import os
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage

from chains.guide_chain import generate_guide
from graph import build_graph

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì „ì—­ ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ (ìƒíƒœ ë¹„ì €ì¥ ë¡œì§, ìƒíƒœëŠ” ì„¸ì…˜ë³„ë¡œ ì „ë‹¬ë¨)
app_graph = build_graph()

async def generate_context(loc, sit):
    """ê°€ì´ë“œë¥¼ ìƒì„±í•˜ê³  ì„¸ì…˜ ìƒíƒœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if not loc or not sit:
        err = {"error": "Please enter location and situation."}
        return err, {}, {}, {}, {}
    
    print(f"Generating guide for {loc} - {sit}...")
    try:
        # ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
        context_data = await generate_guide(loc, sit)
    except Exception as e:
        print(f"Error in generate_guide: {e}")
        err = {"error": f"Error generating guide: {str(e)}"}
        return err, {}, {}, {}, {}
    
    guide_data = context_data.get("guide", {})
    
    
    # ê° í•­ëª© ë¶„ë¦¬ ë° ë§ˆí¬ë‹¤ìš´ ë³€í™˜
    flow_list = guide_data.get("conversation_flow", [])
    flow_md = "\n\n".join(flow_list) if flow_list else "ëŒ€í™” íë¦„ì´ ì—†ìŠµë‹ˆë‹¤."
    
    speaking_list = guide_data.get("speaking_expressions", [])
    speaking_md = "\n".join([f"- {item}" for item in speaking_list]) if speaking_list else "í‘œí˜„ì´ ì—†ìŠµë‹ˆë‹¤."
    
    listening_list = guide_data.get("listening_expressions", [])
    listening_md = "\n".join([f"- {item}" for item in listening_list]) if listening_list else "í‘œí˜„ì´ ì—†ìŠµë‹ˆë‹¤."
    
    vocab_list = guide_data.get("focused_vocabulary", [])
    vocab_md = "\n".join([f"- {item}" for item in vocab_list]) if vocab_list else "ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    return flow_md, speaking_md, listening_md, vocab_md, context_data

async def chat_response(message, history, context, loc, sit):
    """
    LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    history: Gradioì˜ [{"role": "user", "content": ...}, ...] ë¦¬ìŠ¤íŠ¸
    """
    print(f"Gradio Version: {gr.__version__}")
    
    # historyê°€ Noneì¼ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
    if history is None:
        history = []
        
    if not context:
        history.append({"role": "user", "content": message})
        history.append({"role": "assistant", "content": "ë¨¼ì € ê°€ì´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”! (ë²„íŠ¼ í´ë¦­)"})
        yield history, ""
        return
    
    # Gradio ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ë¡œ ë³€í™˜
    messages = []
    for msg in history:
        if isinstance(msg, dict):
            if msg.get("role") == "user":
                messages.append(HumanMessage(content=msg["content"]))
            elif msg.get("role") == "assistant":
                messages.append(AIMessage(content=msg["content"]))
        else:
            # Fallback for tuple format if mixed
            if len(msg) >= 2:
                messages.append(HumanMessage(content=str(msg[0])))
                if msg[1]:
                    messages.append(AIMessage(content=str(msg[1])))
    
    messages.append(HumanMessage(content=message))
    
    # ê·¸ë˜í”„ ì‹¤í–‰
    inputs = {
        "messages": messages,
        "context_data": context,
        "location": loc,
        "situation": sit
    }
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ë¨¼ì € í‘œì‹œ
    history.append({"role": "user", "content": message})
    yield history, ""
    
    try:
        # ë¹„ë™ê¸° ê·¸ë˜í”„ í˜¸ì¶œ
        result = await app_graph.ainvoke(inputs)
        full_response = result["messages"][-1].content
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‹œë®¬ë ˆì´ì…˜ (í•œ ê¸€ìì”© ì¶œë ¥)
        history.append({"role": "assistant", "content": ""})
        for i in range(len(full_response)):
            history[-1]["content"] = full_response[:i+1]
            yield history, ""
            
    except Exception as e:
        error_msg = f"Error: {str(e)}"
        history.append({"role": "assistant", "content": error_msg})
        yield history, ""

# Google Places ë„êµ¬ ì´ˆê¸°í™”
from tools.google_places import GooglePlacesTool
place_tool = GooglePlacesTool()

def update_suggestions(query):
    """ê²€ìƒ‰ì–´ ë³€ê²½ ì‹œ ì¥ì†Œ ì¶”ì²œ ëª©ë¡ ì—…ë°ì´íŠ¸"""
    if not query or len(query) < 2:
        return gr.update(choices=[], visible=False)
    
    try:
        results = place_tool.search_places(query)
        # Dropdown choices: ["Main Text (Full Text)", ...]
        choices = [f"{item['main_text']} ({item['description']})" for item in results]
        return gr.update(choices=choices, visible=True)
    except Exception as e:
        print(f"Suggestion Error: {e}")
        return gr.update(choices=[], visible=False)

def select_place(selected_text):
    """ì¶”ì²œ ì¥ì†Œ ì„ íƒ ì‹œ ì¥ì†Œ ì…ë ¥ì°½ ì±„ìš°ê¸°"""
    if not selected_text:
        return gr.update()
    
    # "Main Text (Full Text)" í˜•ì‹ì—ì„œ Description ë¶€ë¶„ ì¶”ì¶œ ë˜ëŠ” ì „ì²´ ì‚¬ìš©
    # ì—¬ê¸°ì„œëŠ” ê´„í˜¸ í¬í•¨ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, íŒŒì‹±í•´ì„œ ì •ì œí•  ìˆ˜ ìˆìŒ.
    # ì‚¬ìš© í¸ì˜ë¥¼ ìœ„í•´ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
    return selected_text

# UI ë ˆì´ì•„ì›ƒ
with gr.Blocks(title="TripTalker", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# âœˆï¸ TripTalker: ì‹¤ì „ ì—¬í–‰ íšŒí™” ì‹œë®¬ë ˆì´í„°")
    
    # ì„¸ì…˜ ìƒíƒœ
    context_state = gr.State({})
    
    with gr.Row():
        with gr.Column(scale=4 ,min_width=400):
            # Google Places Autocomplete
            gr.Markdown("### ğŸ“ ì¥ì†Œ ê²€ìƒ‰")
            search_input = gr.Textbox(label="ì¥ì†Œ ê²€ìƒ‰", placeholder="ì˜ˆ: ë„ì¿„ ë””ì¦ˆë‹ˆ, ì˜¤ì‚¬ì¹´ ë¼ë©´...", show_label=False)
            suggestion_dropdown = gr.Dropdown(label="ì¶”ì²œ ì¥ì†Œ", visible=False, interactive=True)
            
            gr.Markdown("---")
            location_input = gr.Textbox(label="ì¥ì†Œ / êµ­ê°€ (ìë™ ì…ë ¥ë¨)", placeholder="ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ìœ„ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”")
            situation_input = gr.Textbox(label="ìƒí™©", placeholder="ì˜ˆ: ê³ ìˆ˜ ë¹¼ê³  ë§¤ìš´ ë¼ë©´ ì£¼ë¬¸í•˜ê¸°")
            btn_start = gr.Button("1. ê°€ì´ë“œ ë°›ê¸° & ì‹œì‘", variant="primary")
            
            # ì´ë²¤íŠ¸ ì—°ê²° (UI ë‚´ë¶€ ì •ì˜)
            search_input.change(
                fn=update_suggestions,
                inputs=search_input,
                outputs=suggestion_dropdown
            )
            
            suggestion_dropdown.change( # select ëŒ€ì‹  change ì‚¬ìš© (Dropdown ê°’ ë³€ê²½ ì‹œ)
                fn=select_place,
                inputs=suggestion_dropdown,
                outputs=location_input
            )

            # 1. ëŒ€í™” íë¦„ (ê°€ì¥ ì¤‘ìš”)
            with gr.Tabs():
                with gr.TabItem("ğŸ“– ëŒ€í™” íë¦„"):
                    # JSON ëŒ€ì‹  Markdown ì‚¬ìš©
                    flow_output = gr.Markdown("ê°€ì´ë“œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë‚´ìš©ì´ í‘œì‹œë©ë‹ˆë‹¤.")
            
            # 2. í‘œí˜„ (Speaking / Listening)
                with gr.TabItem("ğŸ—£ï¸ ì£¼ìš” í‘œí˜„"):
                    with gr.Accordion("ë§í•˜ê¸° (Speaking)", open=True):
                        speaking_output = gr.Markdown("- í‘œí˜„ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
                    with gr.Accordion("ë“£ê¸° (Listening)", open=True):
                        listening_output = gr.Markdown("- í‘œí˜„ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
            
            # 3. ë‹¨ì–´ ë° ë©”ë‰´ (í†µí•©)
                with gr.TabItem("word ë‹¨ì–´ì¥"):
                    vocab_output = gr.Markdown("ì¶”ì²œ ë‹¨ì–´ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            
        with gr.Column(scale=6):
            chatbot = gr.Chatbot(label="ì‹œë®¬ë ˆì´ì…˜", height=500)
            msg_input = gr.Textbox(label="ë©”ì‹œì§€ ì…ë ¥", placeholder="ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”... (ì—”í„°ë¡œ ì „ì†¡)")
            clear = gr.Button("ëŒ€í™” ì§€ìš°ê¸°")

    # ì´ë²¤íŠ¸ ì—°ê²°
    btn_start.click(
        generate_context,
        inputs=[location_input, situation_input],
        outputs=[flow_output, speaking_output, listening_output, vocab_output, context_state]
    )
    
    msg_input.submit(
        chat_response,
        inputs=[msg_input, chatbot, context_state, location_input, situation_input],
        outputs=[chatbot, msg_input]
    )

if __name__ == "__main__":
    demo.launch()
