from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from typing import List

from tools.tavily_search import TripSearchTool

class GuideOutput(BaseModel):
    speaking_expressions: List[str] = Field(description="ì—¬í–‰ìê°€ ë§í•  5ê°€ì§€ í•µì‹¬ í‘œí˜„ (íƒ€ê²Ÿ ì–¸ì–´ - ë°œìŒ - í•œêµ­ì–´ ì˜ë¯¸)")
    listening_expressions: List[str] = Field(description="ì—¬í–‰ìê°€ ë“¤ì„ 5ê°€ì§€ í•µì‹¬ í‘œí˜„ (íƒ€ê²Ÿ ì–¸ì–´ - ë°œìŒ - í•œêµ­ì–´ ì˜ë¯¸)")
    focused_vocabulary: List[str] = Field(description="í•´ë‹¹ ì¥ì†Œ/ìƒí™©ì˜ ì£¼ìš” ë‹¨ì–´ ë° ì¶”ì²œ í•­ëª© (ë©”ë‰´ í¬í•¨) 5~7ê°œ")
    conversation_flow: List[str] = Field(description="í‘œì¤€ ëŒ€í™” íë¦„ (ë‹¨ê³„ë³„)")

from database.supabase_client import GuideCache

# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
guide_cache = GuideCache()

from langchain_community.document_loaders import YoutubeLoader
import re
import asyncio

async def fetch_youtube_context(query: str) -> str:
    """
    ìœ íŠœë¸Œ ê²€ìƒ‰(Tavily ê²½ìœ ) í›„ ìë§‰ì„ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    LangChain YoutubeLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ ìë§‰ ì²˜ë¦¬ë¥¼ ê°„ì†Œí™”í•©ë‹ˆë‹¤.
    """
    try:
        search_tool = TripSearchTool()
        # "site:youtube.com"ì„ ë¶™ì—¬ ìœ íŠœë¸Œ ì˜ìƒ ìœ„ì£¼ë¡œ ê²€ìƒ‰
        search_result = await search_tool.search_place_async(f"{query} site:youtube.com")
        results = search_result.get("results", [])
        
        video_ids = []
        for res in results:
            url = res.get("url", "")
            # ìœ íŠœë¸Œ Video ID ì¶”ì¶œ (v=ê°’)
            match = re.search(r"v=([a-zA-Z0-9_-]{11})", url)
            if match:
                video_ids.append(match.group(1))
        
        # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 2ê°œë§Œ ì‚¬ìš©
        video_ids = list(set(video_ids))[:2]
        
        full_transcript = ""
        loop = asyncio.get_running_loop()
        
        for vid in video_ids:
            try:
                # YoutubeLoader ì´ˆê¸°í™” (í•œêµ­ì–´ -> ì˜ì–´ ìˆœ)
                loader = YoutubeLoader.from_youtube_url(
                    f"https://www.youtube.com/watch?v={vid}",
                    add_video_info=False,
                    language=["ko", "en"]
                )
                
                # ë™ê¸° í•¨ìˆ˜ì¸ load()ë¥¼ ë¹„ë™ê¸° ë£¨í”„ë¡œ ì‹¤í–‰í•˜ì—¬ ë¸”ë¡œí‚¹ ë°©ì§€
                docs = await loop.run_in_executor(None, loader.load)
                
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = " ".join([d.page_content for d in docs])
                full_transcript += f"\n[Video {vid}]: {text[:1000]}..."
                
            except Exception as e:
                # ìë§‰ì´ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
                continue
                
        return full_transcript if full_transcript else "No YouTube transcripts found."
        
    except Exception as e:
        print(f"YouTube Search Error: {e}")
        return "YouTube search failed."

class SearchQuery(BaseModel):
    specific_query: str = Field(description="Web search query for specific info (menu, price, tips)")
    general_query: str = Field(description="YouTube search query for broad context (brand name + ordering guide/vlog)")

async def generate_guide(location: str, situation: str):
    # 0. ìºì‹œ í™•ì¸ (0.5ì´ˆ ì»·)
    cached_guide = await guide_cache.search_guide(location, situation)
    if cached_guide:
        return {
            "guide": cached_guide,
            "raw_search": {"summary": "Cached Data"},
            "menu_text": str(cached_guide.get("focused_vocabulary", "Cached vocab")),
            "key_phrases": cached_guide.get("speaking_expressions", []) + cached_guide.get("listening_expressions", [])
        }

    # 1. ê²€ìƒ‰ì–´ ìµœì í™” (Query Refinement) - LLM ì‚¬ìš©
    # ì‚¬ìš©ì ì…ë ¥: "ë„ì¿„ ë””ì¦ˆë‹ˆ ì…êµ¬ ê·¼ì²˜ í¸ì˜ì ", "ë¬¼ì´ë‘ ê°„ì‹ ì‚¬ê¸°"
    # -> Specific: "tokyo disneyland entrance convenience store snack price"
    # -> General: "Japanese convenience store buying snacks vlog" (ë¸Œëœë“œ/ì—…ì¢… ì¶”ì¶œ)
    
    refiner_llm = ChatOpenAI(model="gpt-5-mini", temperature=0)
    refiner_parser = JsonOutputParser(pydantic_object=SearchQuery)
    
    refiner_prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a search query optimizer for a travel guide AI."),
        ("user", """
        Location: {location}
        Situation: {situation}
        
        Generate two search queries:
        1. **specific_query** (for Web): Detailed query to find menu, prices, and tips.
        2. **general_query** (for YouTube): Broad query to find vlogs or ordering guides. 
           - Extract the Core Brand Name or Category (e.g., 'Starbucks', 'McDonalds', 'Convenience Store').
           - Append keywords like 'ordering guide', 'vlog', 'how to order'.
           - If the location is specific (e.g., 'Starbucks Shibuya'), use the Brand Name ('Starbucks') for the general query to get more results.
        
        {format_instructions}
        """)
    ])
    
    refiner_chain = refiner_prompt | refiner_llm | refiner_parser
    
    try:
        # ê²€ìƒ‰ì–´ ìƒì„± (ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ gpt-5-mini ì‚¬ìš©)
        query_result = await refiner_chain.ainvoke({
            "location": location,
            "situation": situation,
            "format_instructions": refiner_parser.get_format_instructions()
        })
        specific_query = query_result.get("specific_query", f"{location} {situation} menu price")
        general_query = query_result.get("general_query", f"{location} ordering vlog")
        
    except Exception as e:
        print(f"Query Refinement Failed: {e}")
        specific_query = f"{location} {situation} menu price tips"
        general_query = f"{location} ordering guide vlog"

    # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search) - ë³‘ë ¬ ì‹¤í–‰
    search_tool = TripSearchTool()
    
    print(f"ğŸš€ Starting Hybrid Search...\n- Specific: {specific_query}\n- General: {general_query}")
    
    # Asyncio Gatherë¡œ ë³‘ë ¬ ì‹¤í–‰
    tavily_task = search_tool.search_place_async(specific_query)
    youtube_task = fetch_youtube_context(general_query)
    
    results = await asyncio.gather(tavily_task, youtube_task)
    search_result = results[0]  # Tavily ê²°ê³¼
    youtube_context = results[1] # YouTube ìë§‰ ê²°ê³¼
    
    context_text = f"""
    [Web Search Result]:
    {search_result.get('text_summary', '')}
    
    [YouTube Vlog Context]:
    {youtube_context}
    """
    
    # 3. ê°€ì´ë“œ ìƒì„±
    llm = ChatOpenAI(model="gpt-5-mini", temperature=0)
    parser = JsonOutputParser(pydantic_object=GuideOutput)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are an expert travel guide creator for Korean travelers."),
        ("user", """
        Location: {location}
        Situation: {situation}
        
        We have gathered information from Web and YouTube Vlogs.
        **Context Info**:
        {context}
        
        1. **Determine the Local Language** of `{location}`.
        2. use **Context Info** to find real expressions, menu items, and ordering tips.
           - If YouTube context contains actual dialogue, prioritize it for "Conversation Flow".
        
        3. **Output Format** (Strictly follow this):
           - Expressions: `[Target Lang] - ([Pronunciation]) - [Meaning]`
           
        4. **Contents**:
           - Speaking/Listening Expressions (5 each)
           - Focused Vocabulary (Menu/Terms)
           - Conversation Flow (Step-by-step dialogue)
        
        {format_instructions}
        """)
    ])
    
    chain = prompt | llm | parser
    
    try:
        # ë¹„ë™ê¸° LLM í˜¸ì¶œ
        guide = await chain.ainvoke({
            "location": location,
            "situation": situation,
            "context": context_text,
            "format_instructions": parser.get_format_instructions()
        })
        
        # 4. ìºì‹œ ì €ì¥ (ë¹„ë™ê¸°ë¡œ ìˆ˜í–‰í•˜ì—¬ ì‚¬ìš©ì ì‘ë‹µ ì†ë„ ì €í•˜ ìµœì†Œí™”)
        # await save_guide(...) waits here. Ideally use create_task but to ensure save use await.
        await guide_cache.save_guide(location, situation, guide)
        
    except Exception as e:
        # ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” í‚¤ ëˆ„ë½ ì‹œ ëŒ€ì²´
        guide = {
            "speaking_expressions": ["I'd like... - (Pronunciation) - Meaning"],
            "listening_expressions": ["For here or to go? - (Pronunciation) - Meaning"],
            "focused_vocabulary": ["Cilantro (ê³ ìˆ˜)", "Spicy (ë§¤ìš´)", "To go (í¬ì¥)"],
            "conversation_flow": [
                "Step 1: [Staff] Hello - (Hello) - (ì•ˆë…•í•˜ì„¸ìš”)",
                "Step 2: [Traveler] Hi - (Hi) - (ì•ˆë…•)"
            ]
        }
        print(f"Guide generation error: {e}")

    # ì±„íŒ… ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë³‘í•©
    full_context = {
        "guide": guide,
        "raw_search": search_result,
        "menu_text": str(guide.get("focused_vocabulary", "No vocab data")),
        # ì—ì´ì „íŠ¸ê°€ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ í‘œí˜„ í†µí•©
        "key_phrases": guide.get("speaking_expressions", []) + guide.get("listening_expressions", [])
    }
    
    return full_context
